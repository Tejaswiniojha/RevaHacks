{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, Input, Model\n",
    "import glob,os\n",
    "# from model import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input_train = \"../data/\"\n",
    "path_label_train = \"../data/\"\n",
    "train_input = glob.glob(os.path.join(path_input_train,\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    reads the image in RGB mode and  resizes it into 224,224. Also normalized the image pixel in range (0-1)\n",
    "    :param image:\n",
    "    :return: image\n",
    "    \"\"\"\n",
    "    img = Image.open(image).convert('RGB')\n",
    "    img_crop = img.resize((224,224), Image.ANTIALIAS)\n",
    "    img_crop = np.array(img_crop)\n",
    "    scaled_img = np.divide(img_crop,255.0)\n",
    "    return scaled_img\n",
    "\n",
    "\n",
    "def create_train_test_set():\n",
    "    \"\"\"\n",
    "    create the data-set. Stores the input image and its corresponding labelled images in two numpy arrays as input and\n",
    "    label. Also splits the whole data-set into train and test.\n",
    "    :return: train_input, train_label, test_input, test_label\n",
    "    \"\"\"\n",
    "    train_input_images, train_label_images = [], []\n",
    "\n",
    "    for image in train_input:\n",
    "        image_name = image.split(\"/\")[-1]\n",
    "        if os.path.exists(os.path.join(path_label_train,image_name)):\n",
    "            train_input_images.append(preprocess_image(image))\n",
    "            train_label_images.append(preprocess_image(os.path.join(path_label_train,image_name)))\n",
    "\n",
    "    train_input_images = np.array(train_input_images)\n",
    "    train_label_images = np.array(train_label_images)\n",
    "    #test_input_images = train_input_images[-100:]\n",
    "    #test_label_images = train_label_images[-100:]\n",
    "    #train_input_images = train_input_images[:-100]\n",
    "    #train_label_images = train_label_images[:-100]\n",
    "\n",
    "    print(\"train_images_length\",len(train_input_images),len(train_label_images))\n",
    "#     print(\"train_images_length\",len(train_input_images))\n",
    "    #print(\"test_images_length\",len(test_input_images),len(test_label_images))\n",
    "    #return train_input_images, train_label_images, test_input_images, test_label_images\n",
    "    return train_input_images, train_label_images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 224, 224, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 214, 214, 96)      11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 214, 214, 96)      384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 106, 106, 96)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPaddi (None, 110, 110, 96)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 106, 106, 256)     614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 106, 106, 256)     1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 52, 52, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 52, 52, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPaddi (None, 54, 54, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 52, 52, 384)       885120    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_27 (ZeroPaddi (None, 54, 54, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 52, 52, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 25, 25, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 160000)            0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              163841024 \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               131200    \n",
      "=================================================================\n",
      "Total params: 166,370,112\n",
      "Trainable params: 166,369,408\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputTensor = Input((224,224,1))\n",
    "\n",
    "conv1 = layers.Conv2D(96,(11,11),strides=1,activation='relu')(inputTensor)\n",
    "\n",
    "conv1_norm = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,center=True,\n",
    "            scale=True, beta_initializer='zeros', gamma_initializer='ones',\n",
    "            moving_mean_initializer='zeros',moving_variance_initializer='ones')(conv1)\n",
    "\n",
    "conv1_pool = layers.MaxPool2D((3,3), 2)(conv1_norm)\n",
    "\n",
    "conv2_padding = layers.ZeroPadding2D((2, 2))(conv1_pool)\n",
    "\n",
    "conv2 = layers.Conv2D(256,(5,5),strides=1,activation='relu')(conv2_padding)\n",
    "conv2_norm = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001,center=True,\n",
    "            scale=True, beta_initializer='zeros', gamma_initializer='ones',\n",
    "            moving_mean_initializer='zeros',moving_variance_initializer='ones')(conv2)\n",
    "\n",
    "conv2_pool = layers.MaxPool2D((3,3), 2)(conv2_norm)\n",
    "\n",
    "conv2_dropout = layers.Dropout(0.3, seed=1)(conv2_pool)\n",
    "\n",
    "conv3_padding = layers.ZeroPadding2D((1,1))(conv2_dropout)\n",
    "\n",
    "conv3 = layers.Conv2D(384, (3,3), strides = 1, activation = 'relu')(conv3_padding)\n",
    "\n",
    "conv4_padding = layers.ZeroPadding2D((1,1))(conv3)\n",
    "\n",
    "conv4 = layers.Conv2D(256, (3,3), strides = 1, activation = 'relu')(conv4_padding)\n",
    "                                                                    \n",
    "conv4_pool = layers.MaxPool2D((3,3), 2)(conv4)\n",
    "                                                                    \n",
    "conv4_dropout = layers.Dropout(0.3, seed=1)(conv4_pool)\n",
    "                                                                    \n",
    "flatten_layer = layers.Flatten()(conv4_dropout)\n",
    "                                                                    \n",
    "fully_connected1 = layers.Dense(1024)(flatten_layer)\n",
    "\n",
    "fc1_dropout = layers.Dropout(0.5, seed=1)(fully_connected1)\n",
    "                                                                    \n",
    "fully_connected2 = layers.Dense(128)(fc1_dropout)\n",
    "                                                                    \n",
    "similarity_model = Model(inputs = [inputTensor], outputs = fully_connected2, name = 'Similarity_Model')\n",
    "                                                                    \n",
    "similarity_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim=(224,224,1)\n",
    "input_anchor = Input(shape=(in_dim))\n",
    "input_positive = Input(shape=(in_dim))\n",
    "input_negative = Input(shape=(in_dim))\n",
    "processed_a=similarity_model(input_a)\n",
    "processed_p=similarity_model(input_p)\n",
    "processed_n=similarity_model(input_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.get_shape of <tf.Tensor 'Similarity_Model_3/dense_14/BiasAdd:0' shape=(?, 128) dtype=float32>>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_a.get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def euclidean_distance_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    :param y_true: TensorFlow/Theano tensor\n",
    "    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dist= euclidean_distance_loss(processed_a, processed_p)\n",
    "negative_dist = euclidean_distance_loss(processed_a, processed_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: <keras.layers.core.Lambda object at 0x7feca80469d0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-c8d04c2091a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpositive_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_dist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_anchor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_positive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_negative\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacked_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'triple_siamese'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/apeksha/.local/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/apeksha/.local/lib/python2.7/site-packages/keras/engine/network.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/apeksha/.local/lib/python2.7/site-packages/keras/engine/network.pyc\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    192\u001b[0m                                  \u001b[0;34m'the output of a Keras `Layer` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                                  \u001b[0;34m'(thus holding past layer metadata). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                                  'Found: ' + str(x))\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         self._compute_previous_mask = (\n",
      "\u001b[0;31mValueError\u001b[0m: Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: <keras.layers.core.Lambda object at 0x7feca80469d0>"
     ]
    }
   ],
   "source": [
    "stacked_dists = layers.Lambda(lambda vects: K.stack(vects, axis=1),name='stacked_dists')\n",
    "([positive_dist, negative_dist])\n",
    "\n",
    "model = Model([input_anchor, input_positive, input_negative], stacked_dists, name='triple_siamese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
